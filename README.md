# NLP ‚Äì An√°lise de Sentimentos em Tweets em Portugu√™s üáßüá∑

Projeto completo de **Processamento de Linguagem Natural (PLN)** para **an√°lise de sentimento** em portugu√™s usando o dataset do Kaggle **‚ÄúPortuguese Tweets for Sentiment Analysis‚Äù** (positivo/negativo/neutro). O projeto inclui todas as etapas da ci√™ncia de dados, com **pr√©-processamento**, **tokeniza√ß√£o**, **normaliza√ß√£o**, **remo√ß√£o de s√≠mbolos**, **stopwords**, **stemming e lematiza√ß√£o**, vetoriza√ß√£o com **TF‚ÄëIDF** e **caracteres**, cria√ß√£o de **embeddings** (*FastText* via *gensim*), **sele√ß√£o/treinamento de modelos**, **compara√ß√£o por m√©tricas**, explicabilidade com **LIME** e **deploy** via CLI e **API FastAPI**.

**Dataset:** Kaggle ‚Äì *Portuguese Tweets for Sentiment Analysis*. Classes: *positive*, *negative*, *neutral*. Os arquivos incluem colunas como `id`, `tweet_text`, `tweet_date`, `sentiment`, `query_used` (conforme descrito por reposit√≥rios que utilizam esse dataset).

---

## üîß Stack e principais bibliotecas

- Python 3.9+
- `pandas`, `numpy`
- `scikit-learn` (modelos cl√°ssicos + m√©tricas)
- `nltk` (stopwords e stemmer RSLP pt-br)
- `spacy` (opcional, lematiza√ß√£o com `pt_core_news_sm`)
- `gensim` (embeddings FastText treinados no pr√≥prio corpus)
- `joblib` (persist√™ncia de artefatos)
- `matplotlib` (gr√°ficos de avalia√ß√£o)
- `kaggle` (download do dataset via API)
- `lime` (explicabilidade por inst√¢ncia)
- `fastapi` + `uvicorn` (servi√ßo de infer√™ncia)

> Extras opcionais: `xgboost`, `torch`/`tensorflow` e `transformers` (para modelos mais pesados).

---

## üóÇÔ∏è Estrutura de Pastas e Arquivos

```
nlp_pt_sa/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.yml.txt
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/          # CSVs originais do Kaggle (ap√≥s download)
‚îÇ   ‚îî‚îÄ‚îÄ processed/    # Dados limpos e prontos p/ modelagem
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ artifacts/    # Vetorizadores, modelos e pipeline salvos
‚îÇ   ‚îî‚îÄ‚îÄ reports/      # M√©tricas, gr√°ficos e leaderboard
‚îú‚îÄ‚îÄ scripts/          # Cada etapa do pipeline em .txt (execut√°vel em Python)
‚îÇ   ‚îú‚îÄ‚îÄ 00_setup_env.txt
‚îÇ   ‚îú‚îÄ‚îÄ 01_download_kaggle.txt
‚îÇ   ‚îú‚îÄ‚îÄ 02_preprocess.txt
‚îÇ   ‚îú‚îÄ‚îÄ 03_vectorize_train_baselines.txt
‚îÇ   ‚îú‚îÄ‚îÄ 04_embeddings_fasttext_train.txt
‚îÇ   ‚îú‚îÄ‚îÄ 05_evaluate_compare.txt
‚îÇ   ‚îú‚îÄ‚îÄ 06_inference_cli.txt
‚îÇ   ‚îî‚îÄ‚îÄ 07_api_fastapi.txt
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ text_utils.txt
    ‚îî‚îÄ‚îÄ ml_utils.txt
```

> **Observa√ß√£o:** Todos os **c√≥digos** do pipeline est√£o em **`.txt`** conforme solicitado. O Python consegue executar arquivos `.txt` normalmente: `python scripts/02_preprocess.txt`. Se preferir, renomeie para `.py`.

---

## ‚öôÔ∏è Instala√ß√£o r√°pida

1) **Crie e ative** um ambiente virtual
```bash
python -m venv .venv
# Windows: 
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate
```

2) **Instale depend√™ncias**
```bash
pip install -r requirements.txt
```

3) **Baixe recursos NLTK e modelo spaCy (opcional, recomendado)**
```bash
python scripts/00_setup_env.txt --with-spacy
```

4) **Configure a API do Kaggle**  
Crie `~/.kaggle/kaggle.json` com suas credenciais ou defina `KAGGLE_USERNAME` e `KAGGLE_KEY` no ambiente.

5) **Baixe o dataset**
```bash
python scripts/01_download_kaggle.txt
```

6) **Pr√©-processamento (tokeniza√ß√£o, normaliza√ß√£o, stopwords, stemming/lematiza√ß√£o)**  
```bash
python scripts/02_preprocess.txt --strip-accents false --lemmatize true --stem false
```

7) **Treinar modelos de baseline (TF‚ÄëIDF / char n‚Äëgrams)**
```bash
python scripts/03_vectorize_train_baselines.txt --models mnb,logreg,svm
```

8) **Embeddings (FastText via gensim) + modelos**
```bash
python scripts/04_embeddings_fasttext_train.txt --models logreg,svm
```

9) **Consolidar resultados e escolher o melhor**
```bash
python scripts/05_evaluate_compare.txt
```

10) **Infer√™ncia por CLI**
```bash
python scripts/06_inference_cli.txt --text "Gostei muito do atendimento, excelente!"
```

11) **API FastAPI**
```bash
uvicorn scripts.07_api_fastapi:app --reload
# ou
python scripts/07_api_fastapi.txt
```

---

## üß™ Modelos testados e m√©tricas

- **Multinomial Naive Bayes** (bag-of-words / TF‚ÄëIDF)
- **Logistic Regression** (TF‚ÄëIDF e embeddings)
- **Linear SVM** (TF‚ÄëIDF e embeddings)

M√©tricas reportadas (valida√ß√£o e teste): *accuracy*, *precision/recall/F1 macro e weighted*, *AUC micro/macro (multiclasse, quando aplic√°vel)*, *matriz de confus√£o* e *leaderboard* consolidado.

---

## üß† Pr√©-processamento e PLN (resumo do que os scripts fazem)

- **Tokeniza√ß√£o:** spaCy (pt) se dispon√≠vel; fallback com regex/NLTK.
- **Normaliza√ß√£o:** lowercasing, URLs/men√ß√µes/hashtags, risadas (‚Äúkkkk‚Äù), repeti√ß√£o de letras, n√∫meros e pontua√ß√£o.
- **Stopwords:** NLTK + lista customizada (‚Äúrt‚Äù, ‚Äúvia‚Äù, etc.).
- **Stemming/Lematiza√ß√£o:** RSLPStemmer (NLTK) e/ou lematiza√ß√£o spaCy (`pt_core_news_sm`).
- **Vetoriza√ß√£o:** TF‚ÄëIDF (palavras e caracteres), *n‚Äëgrams*, `min_df`/`max_df` configur√°veis.
- **Embeddings:** FastText (gensim) treinado no corpus ‚Üí vetor de documento por m√©dia de vetores de palavras.
- **Sele√ß√£o de modelo:** *GridSearchCV* com valida√ß√£o estratificada, `class_weight='balanced'` quando suportado.
- **Persist√™ncia:** modelos/vecs em `models/artifacts/` + m√©tricas em `models/reports/`.

---

## üîé Sobre o dataset

- Reposit√≥rio Kaggle: *Portuguese Tweets for Sentiment Analysis* ‚Äì tweets em **portugu√™s** rotulados em **positivo**, **negativo** e **neutro**.
- Colunas (exemplos comuns no conjunto): `id`, `tweet_text`, `tweet_date`, `sentiment`, `query_used`.
- O pipeline detecta automaticamente o arquivo principal em `data/raw/` e a coluna de texto/label, com *fallbacks* configur√°veis em `config/config.yml.txt`.

---

## ‚úçÔ∏è Licen√ßa

MIT ‚Äì use livremente com atribui√ß√£o. Dados do Kaggle seguem a licen√ßa do fornecedor.

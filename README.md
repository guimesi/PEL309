# LIDâ€‘22 â€” IdentificaÃ§Ã£o de Idiomas em 22+ LÃ­nguas ğŸŒ

Pipeline **reprodutÃ­vel** de *Language Identification (LID)* cobrindo 22+ lÃ­nguas, com foco em **simplicidade, robustez e rastreabilidade**. O projeto entrega um fluxo completo: **EDA**, *split* **estratificado por grupos** (hash do texto normalizado, para evitar vazamento), seleÃ§Ã£o de modelos via **GridSearchCV / HalvingGridSearchCV**, **diagnÃ³sticos anti-overfitting** (OOF, *learning curve*, **Yâ€‘scramble**), **mÃ©tricas por classe e por grupo de *script*** (Latin/CJK/Ãrabe etc.), **Topâ€‘3 accuracy**, salvamento de **artefatos e metadados**.

> **CÃ³digo principal:** `lid22.py` (executÃ¡vel direto)  
> **Dataset:** Kaggle â€” *language-identification-datasst* (Zara Jamshaid). O download Ã© automÃ¡tico via **kagglehub** ou vocÃª pode definir o caminho manualmente via `LANGID_CSV`.

---

## ğŸ”§ Stack (nÃºcleo) e opcionais

- Python 3.9+  
- **NÃºcleo:** `pandas`, `numpy`, `scikit-learn`, `matplotlib`, `joblib`, `kagglehub`
- **Opcionais (ativados automaticamente se instalados):**
  - `gensim` â†’ **Word2Vec/Doc2Vec**
  - `xgboost` â†’ **XGBoost** (com `XGB_USE_GPU=1` para `gpu_hist`, se houver GPU)

---

## ğŸ—‚ï¸ Estrutura de saÃ­das (artefatos)

Ao rodar o script, a pasta `artifacts/` Ã© criada com:

```
artifacts/
â”œâ”€â”€ run_YYYYmmdd-HHMMSS.txt                 # log completo da execuÃ§Ã£o
â”œâ”€â”€ plots_YYYYmmdd-HHMMSS/                  # todas as figuras geradas (EDA, matrizes, etc.)
â”œâ”€â”€ cv_results_<experimento>.csv            # resultados do GridSearch por experimento
â”œâ”€â”€ validation_results.csv                   # leaderboard de validaÃ§Ã£o (macroâ€‘F1)
â”œâ”€â”€ classification_report_test_<best>.json   # relatÃ³rio no TEST
â”œâ”€â”€ errors_test_<best>.csv                   # amostras de erros (por par y_true/y_pred)
â”œâ”€â”€ best_langid_<best>.joblib                # pipeline final salvo (train+val â†’ test)
â”œâ”€â”€ diag_text_leakage.json                   # duplicatas e *leakage* entre splits
â”œâ”€â”€ oof_report_<best>.json                   # OOF (F1 macro + relatÃ³rio)
â”œâ”€â”€ learning_curve_<best>.csv                # learning curve (F1 macro) + figura
â”œâ”€â”€ diag_y_scramble_<best>.csv               # distribuiÃ§Ã£o de scores com rÃ³tulos embaralhados
â””â”€â”€ metadata_ext.json                        # metadados consolidados do experimento
```

> As figuras (EDA, matrizes de confusÃ£o â€œbrutaâ€ e normalizada, confusÃ£o por *script*, barras de F1 etc.) entram em `plots_*` automaticamente.

---

## ğŸ§  Modelos e representaÃ§Ãµes incluÃ­dos

**Sempre disponÃ­veis**  
- **TFâ€‘IDF (caracteres 2â€“5)** + **LinearSVC**  
- **TFâ€‘IDF (palavras 1â€“2)** + **LogisticRegression**

**Se as libs estiverem instaladas**  
- **CountVectorizer (caracteres)** + **MultinomialNB**  
- **Word2Vec**/**Doc2Vec** (via `gensim`) + **LogisticRegression**  
- **TFâ€‘IDF (palavras)** â†’ **SVD** â†’ **XGBoost** (multiâ€‘classe), com suporte a **GPU**

Cada experimento Ã© ajustado por *grid* e comparado por **macroâ€‘F1** na validaÃ§Ã£o. O **melhor** Ã© *refit* em **train+val** e avaliado no **TEST**.

---

## ğŸ“Š MÃ©tricas e relatÃ³rios

- **Accuracy**, **F1 macro/micro** (val/test)  
- **Topâ€‘3 accuracy**  
- **RelatÃ³rio por classe** + **matriz de confusÃ£o** (bruta e normalizada)  
- **MÃ©tricas agregadas por *script*** (Latin, CJK, Ãrabe etc.) e **confusÃ£o por *script***  
- **Anti-overfitting:** OOF (*outâ€‘ofâ€‘fold*), *learning curve*, **Yâ€‘scramble** (mÃºltiplas repetiÃ§Ãµes)

---

## âš™ï¸ InstalaÃ§Ã£o

```bash
# 1) Crie um ambiente
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

# 2) Instale dependÃªncias
pip install -U pandas numpy scikit-learn matplotlib joblib kagglehub
# (opcionais)
pip install -U gensim xgboost
```

> Para baixar do Kaggle via `kagglehub`, configure suas credenciais do Kaggle (ou baixe o CSV manualmente e aponte `LANGID_CSV`).

---

## â–¶ï¸ ExecuÃ§Ã£o rÃ¡pida

### (A) Usando download automÃ¡tico (kagglehub)
```bash
python lid22.py
```

### (B) Indicando o CSV localmente
```bash
# Windows (PowerShell)
$env:LANGID_CSV="C:\caminho\para\language.csv"; python lid22.py

# macOS/Linux
LANGID_CSV=/caminho/para/language.csv python lid22.py
```

Durante a execuÃ§Ã£o vocÃª verÃ¡: amostras, colunas detectadas, EDA, *grid* por experimento, leaderboard de validaÃ§Ã£o, avaliaÃ§Ã£o final no **TEST**, diagnÃ³sticos antiâ€‘overfitting e caminhos dos artefatos salvos.

---

## ğŸ§© VariÃ¡veis de ambiente (principais)

| VariÃ¡vel            | Default | DescriÃ§Ã£o |
|---|---:|---|
| `LANGID_CSV`        | â€”      | Caminho para o CSV (se **nÃ£o** quiser usar `kagglehub`). |
| `RUN_HEAVY`         | `1`    | Ativa modelos â€œpesadosâ€/extras (NB, W2V/D2V, XGBâ€¦). Use `0` p/ rodar sÃ³ o essencial. |
| `SKIP_EDA`          | `0`    | Pula as anÃ¡lises/plots exploratÃ³rios. |
| `CV_FOLDS`          | `3`    | NÃºmero de dobras no CV. |
| `SEARCH_SUBSAMPLE`  | `0`    | Se >0, usa apenas N exemplos do *train* no *grid* (rÃ¡pido p/ *smoke test*). |
| `GS_N_JOBS`         | `CPU`  | *Workers* no *grid*. (`loky`) |
| `USE_HALVING`       | `0`    | Usa `HalvingGridSearchCV` (se disponÃ­vel). |
| `SPLIT_BY_GROUPS`   | `1`    | *Split* 80/10/10 estratificado por **grupos (hash do texto)** â†’ evita vazamento. |
| `ANTI_OVERFITTING`  | `1`    | Executa OOF, *learning curve* e **Yâ€‘scramble**. |
| `Y_SCRAMBLE_N`      | `5`    | NÂº de repetiÃ§Ãµes no Yâ€‘scramble. |
| `CALIB_AT_END`      | `0`    | Calibra **LinearSVC** com `CalibratedClassifierCV` (sigmoid, cv=3). |
| `XGB_USE_GPU`       | `0`    | Define `gpu_hist`/`gpu_predictor` no XGBoost (se GPU disponÃ­vel). |
| `W2V_WORKERS`       | `1`    | *Workers* para treinar Word2Vec/Doc2Vec. |
| `SKL_CACHE`         | â€”      | Cache do `Pipeline`. No Windows Ã© **desabilitado** por padrÃ£o p/ evitar *PicklingError*. |

---

## ğŸ§ª Exemplo de inferÃªncia (fora do `main`)

Depois de uma execuÃ§Ã£o, carregue o melhor pipeline salvo:

```python
import joblib
pipe = joblib.load("artifacts/best_langid_<melhor_experimento>.joblib")

textos = [
    "A vida Ã© bela e a modelagem de dados Ã© fascinante.",
    "The quick brown fox jumps over the lazy dog.",
    "Ù‡Ø°Ø§ Ù…Ø«Ø§Ù„ Ù„Ø¬Ù…Ù„Ø© Ù‚ØµÙŠØ±Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."
]
preds = pipe.predict(textos)
print(list(zip(textos, preds)))
```

> O script tambÃ©m imprime prediÃ§Ãµes em 5 frases de exemplo ao final do `main`.

---

## ğŸ” Boas prÃ¡ticas de robustez implementadas

- **NormalizaÃ§Ã£o NFKC** + *casefold* heurÃ­stico (para textos latinos)  
- **PadronizaÃ§Ã£o de rÃ³tulos** (ex.: â€œPortugeseâ€ â†’ â€œPortugueseâ€)  
- **Split por grupos** (hash de texto normalizado) para evitar duplicatas cruzando *splits*  
- **RelatÃ³rios detalhados** + amostras de erros por par (y\_true/y\_pred)  
- **MÃ©tricas por *script*** para entender confusÃµes entre famÃ­lias de escrita

---

## ğŸ†˜ Troubleshooting

- **Falha no download Kaggle (`kagglehub`)** â†’ Baixe manualmente e defina **`LANGID_CSV`**.  
- **Sem `xgboost`/`gensim`** â†’ Eles sÃ£o **opcionais**; o script executa os bÃ¡sicos (TFâ€‘IDF + LinearSVC/LogReg).  
- **Windows / erro de *pickle* no cache** â†’ O cache do `Pipeline` Ã© **desligado automaticamente** no Windows.  
- **ExecuÃ§Ã£o rÃ¡pida**: `SKIP_EDA=1 RUN_HEAVY=0 SEARCH_SUBSAMPLE=5000 python lid22.py`.

---

## ğŸ“œ LicenÃ§a

Respeita a licenÃ§a e termos do **dataset** no Kaggle.
Baseado no script `lid22.py` com foco em reprodutibilidade, diagnÃ³stico antiâ€‘overfitting e rastreabilidade de artefatos.
